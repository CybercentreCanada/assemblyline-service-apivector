# ApiVector Service

[ApiScout](https://github.com/danielplohmann/apiscout) uses process memory dumps to attempt to recover common Windows 
API calls and then builds a representation of them called an ApiVector. 
 
Initial work for this was done during GeekWeek 5 (https://gitlab.com/GeekWeekV/4.2_malfinder/alsvc_apivector)

See the following links for technical details:

* Academic paper describing ApiScout/ApiVectors and results when applied to the malpedia dataset - https://journal.cecyf.fr/ojs/index.php/cybin/article/view/20
* Code on GitHub - https://github.com/danielplohmann/apiscout
* Blog post - http://byte-atlas.blogspot.com/2017/04/apiscout.html

**NB** : In order for the ApiVector AL service to work you need to

1. Build the database for the host where the memory dump was generated
2. Let the service know what VM generated the memory dump using the submission tags *or* the submission metadata (the AL Cuckoo service will do this automatically)


    # Using submission tags if the memory dump is generated by another service (other than Cuckoo)
    request.add_extracted("/path/to/memdumpfile", "Process Memory Dump",
                    display_name="memdumpfile",
                    submission_tag={
                        "vm_name": "name_of_vm"
                    })
                    
    # Or submission metadata (from command line)
    al-submit -u $AL_USER -p $AL_PASS -s $AL_SERVER -j '{"selected":["ApiVector"], "metadata": {"vm_name": "name_of_vm"}}' -i /path/to/procmemdum.dmp
                        

## Service Configuration

The following service configuration options are available (from the web: avatar -> Services -> ApiVector):

    # Can be configured to use malpedia directly, or pull down multiple databases from the support server
    "malpedia_apikey": "",

    # remote path on support server holding apiscout DBs from VMs used to generate
    # memory dumps
    "apiscout_dbs_remote_path": "apiscout",

    # The apiscout DBs to download and use. There should be one for each VM you have generating process memory dumps
    "apiscout_dbs": [],

    # path to apivector DBs to compare against on the support server
    "apivector_lists_remote_path": "apivector_lists",

    # The apivector DBs to retrieve from the support server
    "apivector_lists": [],

    # Parameters for matching apivector
    # minimum confidence in the apivector to do anything with it
    "min_confidence": 50,
    # min jaccard score to report as implant family
    # from https://journal.cecyf.fr/ojs/index.php/cybin/article/view/2 , you can set this depending on your 
    # tolerance for false positives.
    # Even if set very high, FPs are still possible for samples that share a lot of statically linked code
    # * 0.18 leads to a TPR/FPR of 90.18% and 9.45%
    # * 0.22 leads to a TPR/FPR of 89.10% and 4.74% (closest distance to the (0,1) point)
    # * 0.32 leads to a TPR/FPR of 86.55% and 0.99%
    # * 0.55 leads to a TPR/FPR of 80.72% and 0.09%
    "min_jaccard": 0.40

### ApiScout Database Generation

One of the pre-requisites for ApiScout to work is a database of the available APIs. 
This database needs to be built for **each** VM.

There are two ways you can generate this database:

1. Copy the [apiscout repo](https://github.com/danielplohmann/apiscout/archive/master.zip) into  your analysis VM(s)
and run the apiscout\db_build\DatabaseBuilder.py script, then extract the generated .json file.

2. OR - use the scripts provided in this repo to (hopefully) simplify this:

    * Run `generate_apivector_script.py`. This will download the apiscout repo and base64 encode the zip file inside of 
    a python script: `create_apivector_db.py`
    * Submit this script for 'analysis' to each VM used by Cuckoo. Make sure to set the following submission parameters for Cuckoo:
        * Increase the analysis timeout - the script seems to take about 8 minutes or so
        * Run with 'free=yes' - the monitor seems to slow down the script 
        * pass 'filepickup=c:\\apiscout_db.json' - filepickup is an auxiliary module included in the [al_cuckoo_community](https://bitbucket.org/cse-assemblyline/al_cuckoo_community/src) repo.
        since we're running without the monitor, we need some way to pick up the apiscout DB

Using the AssemblyLine client, you can do something like this:

```
al-submit -u AL_USER -p AL_PASSWORD -s https://AL_SERVER -j '{"selected":["Cuckoo"]}' --srv-spec '{"Cuckoo": {"analysis_timeout": 550, "custom_options": "free=yes,filepickup=c:\\apiscout_db.json"}}' -i create_apivector_db.py >/dev/null
```

Once you've generated the json database files (`apiscout_db.json`), copy them to your support server. For example: on a default appliance 
assuming your VM is named `inetsim_win7`, copy the generated database file to `/opt/al/var/support/apiscout/inetsim_win7.json`.

You'll also have to let the ApiVector service know by adding the filename to `apiscout_dbs` service configuration parameter 
(avatar -> Services -> ApiVector)

